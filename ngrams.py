# Author: Antonio Lang
# Date: 25 February 2023

# load_data pulled from test_script.py
def load_data(fname):
  data = []
  fin = open(fname,'r')
  for line in fin:
    line = line.strip()
    data.append(line)
  fin.close()
  return data


def train_ngram(train_data, n):
    # returns a data structure with the ngrams and their probabilities
    
    ngrams = []
    split_data = []
    for index, line in enumerate(train_data):
        split_data.append(line.split(" "))
        for inner_index in range(n, len(split_data[index])+1):
            ngrams.append(split_data[index][inner_index-n:inner_index])
    n_tokens = len(ngrams)
    unique_tokens = [list(gram) for gram in set(tuple(gram) for gram in ngrams)]
    n_unique = len(unique_tokens)

    unique_counts = []
    for unique in unique_tokens:
        count = 0
        for gram in ngrams:
            if unique == gram: count += 1
        unique_counts.append((unique, count))

def generate_language(ngram_model, max_words) -> str:
    # returns an utterance generated frmo the ngram model
    pass

def calculate_probability(utterance, ngram_model) -> float:
    # returns the probability a given utterance could be 
    # generated by the ngram mdoel
    pass

if __name__ == "__main__":
    train_data = load_data("data1.txt")
    model = train_ngram(train_data, 2)